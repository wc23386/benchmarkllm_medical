{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLaMA Supervised Fine-Tuning\n",
    "\n",
    "This document will take the answers of GPT-4o on the Kababutare Medical Dataset and then fine-tune the LLaMA Model on those answers.\n",
    "\n",
    "The purpose of this exercise is to test whether the LLaMA fine-tuning is able to distill the knowledge of GPT-4o and improve the performance on the open-ended question/answering related to healthcare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "MPS available: True\n",
      "MPS built: True\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "# If you want to use MPS (Apple Silicon)\n",
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"MPS built: {torch.backends.mps.is_built()}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unsloth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel, is_bfloat16_supported, train_on_responses_only\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments, DataCollatorForSeq2Seq\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unsloth'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported, train_on_responses_only\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the Question and Answer Pairs from Training Dataset Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_list = []\n",
    "gpt_resp_list = []\n",
    "\n",
    "with open('phase2_data_kabatubare/train_kabatubare.jsonl', 'rb') as file: #only reading the training dataset\n",
    "    for line in file:\n",
    "        json_object = json.loads(line)\n",
    "        ques_list.append(json_object['question'])\n",
    "        gpt_resp_list.append(json_object['gpt_response_base']) #getting GPT Responses from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>gpt_response_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have a small dull ache in my left testicle a...</td>\n",
       "      <td>It's not uncommon for individuals to experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i've heard conflicting opinions. 7 weeks of pr...</td>\n",
       "      <td>During pregnancy, there are several dietary re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my friend slept over that had fever blisters. ...</td>\n",
       "      <td>I understand that you're feeling very anxious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what are some common food triggers for migraines?</td>\n",
       "      <td>Migraines can be triggered by a variety of fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>why does grey hair itch so much? . why does my...</td>\n",
       "      <td>Itching in gray hair can be attributed to seve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18744</th>\n",
       "      <td>how to make money online? . a brand new approa...</td>\n",
       "      <td>I'm here to assist with health-related inquiri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18745</th>\n",
       "      <td>what can i eat with the stomach flu? . i can't...</td>\n",
       "      <td>When you're dealing with stomach flu (viral ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18746</th>\n",
       "      <td>what exams and tests help doctors to evaluate ...</td>\n",
       "      <td>To evaluate or test individuals for ringworm o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18747</th>\n",
       "      <td>could i be pregnant?</td>\n",
       "      <td>Whether you could be pregnant depends on sever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18748</th>\n",
       "      <td>if i have an anal fissure should i see a gastr...</td>\n",
       "      <td>If you have an anal fissure, it's usually appr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18749 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      i have a small dull ache in my left testicle a...   \n",
       "1      i've heard conflicting opinions. 7 weeks of pr...   \n",
       "2      my friend slept over that had fever blisters. ...   \n",
       "3      what are some common food triggers for migraines?   \n",
       "4      why does grey hair itch so much? . why does my...   \n",
       "...                                                  ...   \n",
       "18744  how to make money online? . a brand new approa...   \n",
       "18745  what can i eat with the stomach flu? . i can't...   \n",
       "18746  what exams and tests help doctors to evaluate ...   \n",
       "18747                               could i be pregnant?   \n",
       "18748  if i have an anal fissure should i see a gastr...   \n",
       "\n",
       "                                       gpt_response_base  \n",
       "0      It's not uncommon for individuals to experienc...  \n",
       "1      During pregnancy, there are several dietary re...  \n",
       "2      I understand that you're feeling very anxious ...  \n",
       "3      Migraines can be triggered by a variety of fac...  \n",
       "4      Itching in gray hair can be attributed to seve...  \n",
       "...                                                  ...  \n",
       "18744  I'm here to assist with health-related inquiri...  \n",
       "18745  When you're dealing with stomach flu (viral ga...  \n",
       "18746  To evaluate or test individuals for ringworm o...  \n",
       "18747  Whether you could be pregnant depends on sever...  \n",
       "18748  If you have an anal fissure, it's usually appr...  \n",
       "\n",
       "[18749 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_inf_data = pd.DataFrame({'question': ques_list, 'gpt_response_base': gpt_resp_list})\n",
    "gpt_inf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the HuggingFace Dataset from Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'gpt_response_base'],\n",
       "        num_rows: 16874\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'gpt_response_base'],\n",
       "        num_rows: 1875\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(gpt_inf_data)\n",
    "dataset = dataset.train_test_split(test_size=0.1) #dividing the training dataset into further train:validation dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.2.\n",
      "   \\\\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 47.413 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length = 2048,\n",
    "    load_in_4bit = False, # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = True, # [NEW!] A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "    dtype=None, #None for auto-detection. Can be torch.bfloat16 or torch.float16 (will be automatically detected)\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the PEFT settings for the model\n",
    "\n",
    "https://huggingface.co/blog/damjan-k/rslora\\\n",
    "https://medium.com/@fartypantsham/what-rank-r-and-alpha-to-use-in-lora-in-llm-1b4f025fd133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 64, #max_full_rank=64 by default in FastLanguageModel\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 64, #scaling_factor = lora_alpha/r. If we select lora_alpha = 2 * r then it will multiply the adapter weights by 2 which can be un-ncessary\n",
    "    lora_dropout = 0.1,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    use_rslora = True,\n",
    "    loftq_config = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forming the chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply the chat template\n",
    "def format_chat_template(example):\n",
    "        \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a medical knowledge assistant trained to provide information and guidance on various health-related topics.\"},\n",
    "        {\"role\": \"user\", \"content\": example['question']},\n",
    "        {\"role\": \"assistant\", \"content\": example['gpt_response_base']}\n",
    "    ]\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    return {\"text\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 16874/16874 [00:02<00:00, 5761.89 examples/s]\n",
      "Map: 100%|██████████| 1875/1875 [00:00<00:00, 5723.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_formatted = dataset.map(format_chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 02 Apr 2025\n",
      "\n",
      "You are a medical knowledge assistant trained to provide information and guidance on various health-related topics.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "can osteoarthritis be prevented?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Osteoarthritis (OA) is a degenerative joint disease that occurs when the cartilage that cushions the ends of bones wears down over time. While it cannot be entirely prevented, there are several strategies that may help reduce the risk of developing osteoarthritis or slow its progression. Here are some preventive measures:\n",
      "\n",
      "1. **Maintain a Healthy Weight:** Excess weight puts additional stress on joints, particularly those that bear weight, such as the knees and hips. Maintaining a healthy weight can reduce the risk of OA.\n",
      "\n",
      "2. **Stay Active:** Regular physical activity strengthens the muscles around the joints, improves flexibility, and helps maintain a healthy weight. Low-impact exercises, such as swimming, cycling, or walking, can be beneficial.\n",
      "\n",
      "3. **Protect Joints:** Avoid repetitive motions and overuse of joints. When engaging in activities that strain the joints, use proper techniques and protective gear.\n",
      "\n",
      "4. **Strength Training:** Strengthening the muscles around your joints can help provide better support and may decrease the risk of osteoarthritis.\n",
      "\n",
      "5. **Balanced Diet:** A diet rich in anti-inflammatory foods, such as fruits, vegetables, whole grains, and healthy fats (like omega-3 fatty acids from fish), may help reduce inflammation in the body and support joint health.\n",
      "\n",
      "6. **Stay Hydrated:** Proper hydration is important for cartilage health, as it helps maintain the viscosity of synovial fluid, which lubricates the joints.\n",
      "\n",
      "7. **Avoid Injury:** Take precautions to avoid joint injuries, which can increase the risk of developing osteoarthritis later in life.\n",
      "\n",
      "8. **Regular Check-Ups:** Stay on top of any underlying health conditions, such as metabolic disorders or previous joint injuries, with regular medical check-ups.\n",
      "\n",
      "9. **Care for Existing Joint Problems:** If you have existing joint pain or injuries, addressing them with the help of a healthcare professional can help prevent further damage.\n",
      "\n",
      "While these strategies may be helpful, they do not guarantee that osteoarthritis can be prevented. Genetics and age are significant risk factors that cannot be controlled. However, adopting a healthy lifestyle can potentially decrease the intensity of symptoms if osteoarthritis does develop. Always consult with a healthcare professional for personalized advice and recommendations.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset_formatted['train']['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the TRL SFTTrainer and related Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|██████████| 16874/16874 [00:11<00:00, 1522.06 examples/s]\n",
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|██████████| 1875/1875 [00:02<00:00, 862.30 examples/s] \n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# full_model_path = \"./llama32-sft-full-kabatubare\" #use for full finetuning\n",
    "peft_model_path = \"./llama32-sft-peft-kabatubare\" #use for LoRA based fine-tuning\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=peft_model_path,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        # gradient_accumulation_steps=4,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=50,\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=50,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=1000,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 3,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        seed = 42,\n",
    "        report_to = \"none\",\n",
    "    )\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset=dataset_formatted[\"train\"],\n",
    "    eval_dataset=dataset_formatted[\"test\"],\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = 2048,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer), #only use when using train_on_responses_only()\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'gpt_response_base', 'text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 16874\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 02 Apr 2025\n",
      "\n",
      "You are a medical knowledge assistant trained to provide information and guidance on various health-related topics.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "can osteoarthritis be prevented?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Osteoarthritis (OA) is a degenerative joint disease that occurs when the cartilage that cushions the ends of bones wears down over time. While it cannot be entirely prevented, there are several strategies that may help reduce the risk of developing osteoarthritis or slow its progression. Here are some preventive measures:\n",
      "\n",
      "1. **Maintain a Healthy Weight:** Excess weight puts additional stress on joints, particularly those that bear weight, such as the knees and hips. Maintaining a healthy weight can reduce the risk of OA.\n",
      "\n",
      "2. **Stay Active:** Regular physical activity strengthens the muscles around the joints, improves flexibility, and helps maintain a healthy weight. Low-impact exercises, such as swimming, cycling, or walking, can be beneficial.\n",
      "\n",
      "3. **Protect Joints:** Avoid repetitive motions and overuse of joints. When engaging in activities that strain the joints, use proper techniques and protective gear.\n",
      "\n",
      "4. **Strength Training:** Strengthening the muscles around your joints can help provide better support and may decrease the risk of osteoarthritis.\n",
      "\n",
      "5. **Balanced Diet:** A diet rich in anti-inflammatory foods, such as fruits, vegetables, whole grains, and healthy fats (like omega-3 fatty acids from fish), may help reduce inflammation in the body and support joint health.\n",
      "\n",
      "6. **Stay Hydrated:** Proper hydration is important for cartilage health, as it helps maintain the viscosity of synovial fluid, which lubricates the joints.\n",
      "\n",
      "7. **Avoid Injury:** Take precautions to avoid joint injuries, which can increase the risk of developing osteoarthritis later in life.\n",
      "\n",
      "8. **Regular Check-Ups:** Stay on top of any underlying health conditions, such as metabolic disorders or previous joint injuries, with regular medical check-ups.\n",
      "\n",
      "9. **Care for Existing Joint Problems:** If you have existing joint pain or injuries, addressing them with the help of a healthcare professional can help prevent further damage.\n",
      "\n",
      "While these strategies may be helpful, they do not guarantee that osteoarthritis can be prevented. Genetics and age are significant risk factors that cannot be controlled. However, adopting a healthy lifestyle can potentially decrease the intensity of symptoms if osteoarthritis does develop. Always consult with a healthcare professional for personalized advice and recommendations.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(trainer.train_dataset['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Focus on the `Response Part` for the generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 16874/16874 [00:03<00:00, 4395.88 examples/s]\n",
      "Map (num_proc=64): 100%|██████████| 1875/1875 [00:02<00:00, 700.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'gpt_response_base', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 16874\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 46,\n",
       " 5455,\n",
       " 78,\n",
       " 277,\n",
       " 40485,\n",
       " 320,\n",
       " 42439,\n",
       " 8,\n",
       " 374,\n",
       " 264,\n",
       " 5367,\n",
       " 75989,\n",
       " 10496,\n",
       " 8624,\n",
       " 430,\n",
       " 13980,\n",
       " 994,\n",
       " 279,\n",
       " 7558,\n",
       " 88076,\n",
       " 430,\n",
       " 68241,\n",
       " 279,\n",
       " 10548,\n",
       " 315,\n",
       " 25896,\n",
       " 38400,\n",
       " 1523,\n",
       " 927,\n",
       " 892,\n",
       " 13,\n",
       " 6104,\n",
       " 433,\n",
       " 4250,\n",
       " 387,\n",
       " 11622,\n",
       " 32098,\n",
       " 11,\n",
       " 1070,\n",
       " 527,\n",
       " 3892,\n",
       " 15174,\n",
       " 430,\n",
       " 1253,\n",
       " 1520,\n",
       " 8108,\n",
       " 279,\n",
       " 5326,\n",
       " 315,\n",
       " 11469,\n",
       " 52368,\n",
       " 78,\n",
       " 277,\n",
       " 40485,\n",
       " 477,\n",
       " 6435,\n",
       " 1202,\n",
       " 33824,\n",
       " 13,\n",
       " 5810,\n",
       " 527,\n",
       " 1063,\n",
       " 71123,\n",
       " 11193,\n",
       " 1473,\n",
       " 16,\n",
       " 13,\n",
       " 3146,\n",
       " 67834,\n",
       " 467,\n",
       " 264,\n",
       " 44454,\n",
       " 16923,\n",
       " 68063,\n",
       " 1398,\n",
       " 1140,\n",
       " 4785,\n",
       " 9711,\n",
       " 5217,\n",
       " 8631,\n",
       " 389,\n",
       " 35358,\n",
       " 11,\n",
       " 8104,\n",
       " 1884,\n",
       " 430,\n",
       " 11984,\n",
       " 4785,\n",
       " 11,\n",
       " 1778,\n",
       " 439,\n",
       " 279,\n",
       " 31624,\n",
       " 323,\n",
       " 43523,\n",
       " 13,\n",
       " 43987,\n",
       " 2101,\n",
       " 264,\n",
       " 9498,\n",
       " 4785,\n",
       " 649,\n",
       " 8108,\n",
       " 279,\n",
       " 5326,\n",
       " 315,\n",
       " 81542,\n",
       " 382,\n",
       " 17,\n",
       " 13,\n",
       " 3146,\n",
       " 39202,\n",
       " 10106,\n",
       " 68063,\n",
       " 29900,\n",
       " 7106,\n",
       " 5820,\n",
       " 96931,\n",
       " 279,\n",
       " 24569,\n",
       " 2212,\n",
       " 279,\n",
       " 35358,\n",
       " 11,\n",
       " 36050,\n",
       " 25152,\n",
       " 11,\n",
       " 323,\n",
       " 8779,\n",
       " 10519,\n",
       " 264,\n",
       " 9498,\n",
       " 4785,\n",
       " 13,\n",
       " 12310,\n",
       " 12,\n",
       " 58400,\n",
       " 23783,\n",
       " 11,\n",
       " 1778,\n",
       " 439,\n",
       " 24269,\n",
       " 11,\n",
       " 33162,\n",
       " 11,\n",
       " 477,\n",
       " 11689,\n",
       " 11,\n",
       " 649,\n",
       " 387,\n",
       " 24629,\n",
       " 382,\n",
       " 18,\n",
       " 13,\n",
       " 3146,\n",
       " 62647,\n",
       " 622,\n",
       " 14737,\n",
       " 68063,\n",
       " 35106,\n",
       " 59177,\n",
       " 54245,\n",
       " 323,\n",
       " 927,\n",
       " 817,\n",
       " 315,\n",
       " 35358,\n",
       " 13,\n",
       " 3277,\n",
       " 23387,\n",
       " 304,\n",
       " 7640,\n",
       " 430,\n",
       " 26800,\n",
       " 279,\n",
       " 35358,\n",
       " 11,\n",
       " 1005,\n",
       " 6300,\n",
       " 12823,\n",
       " 323,\n",
       " 29219,\n",
       " 14787,\n",
       " 382,\n",
       " 19,\n",
       " 13,\n",
       " 3146,\n",
       " 53957,\n",
       " 16543,\n",
       " 68063,\n",
       " 36772,\n",
       " 18972,\n",
       " 287,\n",
       " 279,\n",
       " 24569,\n",
       " 2212,\n",
       " 701,\n",
       " 35358,\n",
       " 649,\n",
       " 1520,\n",
       " 3493,\n",
       " 2731,\n",
       " 1862,\n",
       " 323,\n",
       " 1253,\n",
       " 18979,\n",
       " 279,\n",
       " 5326,\n",
       " 315,\n",
       " 52368,\n",
       " 78,\n",
       " 277,\n",
       " 40485,\n",
       " 382,\n",
       " 20,\n",
       " 13,\n",
       " 3146,\n",
       " 38989,\n",
       " 4979,\n",
       " 27304,\n",
       " 68063,\n",
       " 362,\n",
       " 10173,\n",
       " 9257,\n",
       " 304,\n",
       " 7294,\n",
       " 67595,\n",
       " 15657,\n",
       " 11,\n",
       " 1778,\n",
       " 439,\n",
       " 26390,\n",
       " 11,\n",
       " 24822,\n",
       " 11,\n",
       " 4459,\n",
       " 41936,\n",
       " 11,\n",
       " 323,\n",
       " 9498,\n",
       " 50127,\n",
       " 320,\n",
       " 4908,\n",
       " 34998,\n",
       " 12,\n",
       " 18,\n",
       " 40085,\n",
       " 33969,\n",
       " 505,\n",
       " 7795,\n",
       " 705,\n",
       " 1253,\n",
       " 1520,\n",
       " 8108,\n",
       " 37140,\n",
       " 304,\n",
       " 279,\n",
       " 2547,\n",
       " 323,\n",
       " 1862,\n",
       " 10496,\n",
       " 2890,\n",
       " 382,\n",
       " 21,\n",
       " 13,\n",
       " 3146,\n",
       " 39202,\n",
       " 10320,\n",
       " 3696,\n",
       " 660,\n",
       " 68063,\n",
       " 65658,\n",
       " 88000,\n",
       " 374,\n",
       " 3062,\n",
       " 369,\n",
       " 7558,\n",
       " 88076,\n",
       " 2890,\n",
       " 11,\n",
       " 439,\n",
       " 433,\n",
       " 8779,\n",
       " 10519,\n",
       " 279,\n",
       " 99530,\n",
       " 315,\n",
       " 6925,\n",
       " 869,\n",
       " 532,\n",
       " 15962,\n",
       " 11,\n",
       " 902,\n",
       " 54494,\n",
       " 988,\n",
       " 279,\n",
       " 35358,\n",
       " 382,\n",
       " 22,\n",
       " 13,\n",
       " 3146,\n",
       " 53216,\n",
       " 66176,\n",
       " 68063,\n",
       " 12040,\n",
       " 61003,\n",
       " 311,\n",
       " 5766,\n",
       " 10496,\n",
       " 15319,\n",
       " 11,\n",
       " 902,\n",
       " 649,\n",
       " 5376,\n",
       " 279,\n",
       " 5326,\n",
       " 315,\n",
       " 11469,\n",
       " 52368,\n",
       " 78,\n",
       " 277,\n",
       " 40485,\n",
       " 3010,\n",
       " 304,\n",
       " 2324,\n",
       " 382,\n",
       " 23,\n",
       " 13,\n",
       " 3146,\n",
       " 31504,\n",
       " 4343,\n",
       " 35681,\n",
       " 1725,\n",
       " 68063,\n",
       " 29837,\n",
       " 389,\n",
       " 1948,\n",
       " 315,\n",
       " 904,\n",
       " 16940,\n",
       " 2890,\n",
       " 4787,\n",
       " 11,\n",
       " 1778,\n",
       " 439,\n",
       " 41861,\n",
       " 24673,\n",
       " 477,\n",
       " 3766,\n",
       " 10496,\n",
       " 15319,\n",
       " 11,\n",
       " 449,\n",
       " 5912,\n",
       " 6593,\n",
       " 1817,\n",
       " 27859,\n",
       " 382,\n",
       " 24,\n",
       " 13,\n",
       " 3146,\n",
       " 33099,\n",
       " 369,\n",
       " 69571,\n",
       " 30833,\n",
       " 45635,\n",
       " 68063,\n",
       " 1442,\n",
       " 499,\n",
       " 617,\n",
       " 6484,\n",
       " 10496,\n",
       " 6784,\n",
       " 477,\n",
       " 15319,\n",
       " 11,\n",
       " 28118,\n",
       " 1124,\n",
       " 449,\n",
       " 279,\n",
       " 1520,\n",
       " 315,\n",
       " 264,\n",
       " 18985,\n",
       " 6721,\n",
       " 649,\n",
       " 1520,\n",
       " 5471,\n",
       " 4726,\n",
       " 5674,\n",
       " 382,\n",
       " 8142,\n",
       " 1521,\n",
       " 15174,\n",
       " 1253,\n",
       " 387,\n",
       " 11190,\n",
       " 11,\n",
       " 814,\n",
       " 656,\n",
       " 539,\n",
       " 15803,\n",
       " 430,\n",
       " 52368,\n",
       " 78,\n",
       " 277,\n",
       " 40485,\n",
       " 649,\n",
       " 387,\n",
       " 32098,\n",
       " 13,\n",
       " 84386,\n",
       " 323,\n",
       " 4325,\n",
       " 527,\n",
       " 5199,\n",
       " 5326,\n",
       " 9547,\n",
       " 430,\n",
       " 4250,\n",
       " 387,\n",
       " 14400,\n",
       " 13,\n",
       " 4452,\n",
       " 11,\n",
       " 48810,\n",
       " 264,\n",
       " 9498,\n",
       " 19433,\n",
       " 649,\n",
       " 13893,\n",
       " 18979,\n",
       " 279,\n",
       " 21261,\n",
       " 315,\n",
       " 13803,\n",
       " 422,\n",
       " 52368,\n",
       " 78,\n",
       " 277,\n",
       " 40485,\n",
       " 1587,\n",
       " 2274,\n",
       " 13,\n",
       " 24119,\n",
       " 8666,\n",
       " 449,\n",
       " 264,\n",
       " 18985,\n",
       " 6721,\n",
       " 369,\n",
       " 35649,\n",
       " 9650,\n",
       " 323,\n",
       " 19075,\n",
       " 13,\n",
       " 128009]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The labels are created which only contain response. Left Padding is implemented and all the padding tokens are given a score of -100 to avoid loss calculation for pad_tokens\n",
    "trainer.train_dataset['labels'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model and tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just save the LoRA Adapters without merging with base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_path = \"./llama32-sft-peft-kabatubare\" #use for LoRA based fine-tuning\n",
    "\n",
    "# Or run the two below statements\n",
    "model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_model_path = \"./llama32-sft-full-kabatubare\"\n",
    "peft_model_path = \"./llama32-sft-peft-kabatubare\" #use for LoRA based fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = peft_model_path,\n",
    "    max_seq_length = 2048,\n",
    "    load_in_4bit = False, # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "    dtype=None, #None for auto-detection. Can be torch.bfloat16 or torch.float16 (will be automatically detected)\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# for idx in range(1,50):\n",
    "\n",
    "idx = 0\n",
    "\n",
    "print(dataset['test']['question'][idx])\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a medical knowledge assistant trained to provide information and guidance on various health-related topics.\"},\n",
    "            {\"role\": \"user\", \"content\": dataset['test']['question'][idx]}]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(model.device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=2048, num_return_sequences=1)\n",
    "\n",
    "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(text.split(\"assistant\")[1])\n",
    "\n",
    "print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
